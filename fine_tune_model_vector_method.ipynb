{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "fine_tune_model_custom_dataloader_modified_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e65dbda1f65b482bb7cad92601ad6ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_49eae5dfdca64cf599a672bc8088c3b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5b0a45d47434261bb9595a3134e61c0",
              "IPY_MODEL_ea74e8fafed6426382c1b119c99d0464"
            ]
          }
        },
        "49eae5dfdca64cf599a672bc8088c3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5b0a45d47434261bb9595a3134e61c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6679ea2005f542c1b397926c10c86900",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d9689c6cc1f41eaa546e56e9cd1b5a6"
          }
        },
        "ea74e8fafed6426382c1b119c99d0464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8cee8e3120494f6da6bfeed452e59d12",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [30:05&lt;00:00, 25.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_929aa998a8d8490bbaafeba831c03bc5"
          }
        },
        "6679ea2005f542c1b397926c10c86900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d9689c6cc1f41eaa546e56e9cd1b5a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cee8e3120494f6da6bfeed452e59d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "929aa998a8d8490bbaafeba831c03bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomaschen20/satelite-damage-detection/blob/master/fine_tune_model_vector_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNHS-z78lqOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxdo7otsmP3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "f22b8641-720c-4682-ce8f-6ad06de303a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUXbZcu5lqOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9f37c793-e8f0-4223-c455-f274ec6cb1e8"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from damage_detection_functions import *\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import json\n",
        "import random\n",
        "from PIL import Image\n",
        "import pprint\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.6.0+cu101\n",
            "Torchvision Version:  0.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okXKf6KrlqOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model_name = \"resnet\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 4\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 16\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 100\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "input_type = 'pre_and_post' #pre_and_post, post_only, or pre_post_damage_type"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiTvB14vlqPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6122f8e0-eb42-48d0-b5c8-f1bc699b46ba"
      },
      "source": [
        "with open(os.path.join('/content/drive/My Drive/Research Project', 'dataset_google_drive.json')) as f:\n",
        "   root_dir = json.load(f)\n",
        "for image_filename in root_dir:\n",
        "    print(image_filename)\n",
        "    print(root_dir[image_filename]['damage_type'])\n",
        "    break\n",
        "#print(len(sorted(list(root_dir.keys()))))\n",
        "#print(root_dir[image])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Research Project/train/images/guatemala-volcano_00000000_post_disaster.png\n",
            "volcano\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWDfdy5LlqPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, model_type, num_epochs=25):\n",
        "    assert model_type in ['post_only', 'pre_and_post', 'pre_post_damage_type']\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            if model_type == 'post_only':\n",
        "              # Iterate over data.\n",
        "              for inputs, labels in dataloaders[phase]:\n",
        "                  inputs = inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "                  # zero the parameter gradients\n",
        "                  optimizer.zero_grad()\n",
        "                  # forward\n",
        "                  # track history if only in train\n",
        "                  with torch.set_grad_enabled(phase == 'train'):\n",
        "                      \n",
        "                      # Get model outputs and calculate loss\n",
        "                      outputs = model(inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      # backward + optimize only if in training phase\n",
        "                      if phase == 'train':\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "            elif model_type == 'pre_and_post':\n",
        "              # Iterate over data.\n",
        "              for pre_inputs, post_inputs, labels in dataloaders[phase]:\n",
        "                  processed_inputs = torch.cat([post_inputs, pre_inputs], dim=0)\n",
        "                  processed_inputs = processed_inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "                  # zero the parameter gradients\n",
        "                  optimizer.zero_grad()\n",
        "                  # forward\n",
        "                  # track history if only in train\n",
        "                  with torch.set_grad_enabled(phase == 'train'):\n",
        "                      # Get model outputs and calculate loss\n",
        "                      outputs = model(processed_inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      # backward + optimize only if in training phase\n",
        "                      if phase == 'train':\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "            elif model_type == 'pre_post_damage_type':\n",
        "              # Iterate over data.\n",
        "              for pre_inputs, post_inputs, labels, damage_type_input in dataloaders[phase]:\n",
        "                  one_hot = torch.zeros(6)\n",
        "                  one_hot[damage_type] = 1\n",
        "                  processed_inputs = torch.cat([post_inputs, pre_inputs, one_hot], dim=0)\n",
        "                  processed_inputs = processed_inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "                  # zero the parameter gradients\n",
        "                  optimizer.zero_grad()\n",
        "                  # forward\n",
        "                  # track history if only in train\n",
        "                  with torch.set_grad_enabled(phase == 'train'):\n",
        "                      # Get model outputs and calculate loss\n",
        "                      outputs = model(processed_inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      # backward + optimize only if in training phase\n",
        "                      if phase == 'train':\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "        # deep copy the model\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        if phase == 'val':\n",
        "            val_acc_history.append(epoch_acc)\n",
        "            val_loss_history.append(epoch_loss)\n",
        "        else:\n",
        "            train_acc_history.append(epoch_acc)\n",
        "            train_loss_history.append(epoch_loss)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_acc_history, val_acc_history, train_loss_history, val_loss_history"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2zt_VvClqPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mean = np.array([0.485, 0.456, 0.406])\n",
        "#std = np.array([0.229, 0.224, 0.225])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UdCpQ5TJlqPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataloaders = dataloaders_dict\n",
        "#for inputs, labels in dataloaders['train']:\n",
        "#    print(inputs.shape)\n",
        "#    for i in range(8):\n",
        "#        image = np.array(inputs[i])\n",
        "#        image = np.transpose(image, (1, 2, 0))\n",
        "#        image *= std\n",
        "#        image += mean\n",
        "#        image *= 255\n",
        "#        image = image.astype(\"uint8\")\n",
        "#        plt.imshow(image)\n",
        "#        plt.show()\n",
        "#        print(labels[i])\n",
        "#    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKC4QGHrlqQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9I0hIbKlqQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        \n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        \n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOrn5w6DlqQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e65dbda1f65b482bb7cad92601ad6ef0",
            "49eae5dfdca64cf599a672bc8088c3b5",
            "a5b0a45d47434261bb9595a3134e61c0",
            "ea74e8fafed6426382c1b119c99d0464",
            "6679ea2005f542c1b397926c10c86900",
            "9d9689c6cc1f41eaa546e56e9cd1b5a6",
            "8cee8e3120494f6da6bfeed452e59d12",
            "929aa998a8d8490bbaafeba831c03bc5"
          ]
        },
        "outputId": "a2eca6fc-0fe2-4051-cc6d-81d968c224b5"
      },
      "source": [
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "model_ft = nn.Sequential(*(list(model_ft.children())[:-1]))\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e65dbda1f65b482bb7cad92601ad6ef0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (5): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (6): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (7): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5v26yXVlqQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_transforms = transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "model_ft = model_ft.to(device)\n",
        "def output_from_cnn(model_ft, crop):\n",
        "    image_tensor = test_transforms(crop).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input = image_tensor\n",
        "    input = input.to(device)\n",
        "    \n",
        "    output = model_ft(input)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVapTGbrpAIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "97d10210-4fd5-44a5-a764-54e9ad3fec62"
      },
      "source": [
        "!pip install --upgrade Pillow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/bf/92385b4262178ca22b34f82e0e09c2922eb351fe39f3cc7b8ba9ea555b41/Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 3.4MB/s \n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed Pillow-7.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGKxt4MxlqRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "63459202-9eee-4471-9c63-a4fabff1c1f7"
      },
      "source": [
        "from tqdm import tqdm\n",
        "for image_filename in tqdm(root_dir):\n",
        "    image = cv2.imread(image_filename)[:,:,::-1].astype(\"uint8\")\n",
        "    if 'post_disaster' in image_filename:\n",
        "        path = '/content/drive/My Drive/Research Project/tensors/post'\n",
        "    else:\n",
        "        path = '/content/drive/My Drive/Research Project/tensors/pre'\n",
        "    building_index = 0\n",
        "    for building in root_dir[image_filename]['building_list']:\n",
        "        bbox = building['bbox']\n",
        "        x, y, width, height = bbox\n",
        "        if ('pre_disaster' in image_filename) or (building['damage_level'] != 'un-classified'):\n",
        "            crop = image[int(y):int(y+height), int(x):int(x+width), :]\n",
        "            try:\n",
        "              vector = output_from_cnn(model_ft, Image.fromarray(crop))\n",
        "              vector = vector.cpu().detach().numpy()\n",
        "              np.save(os.path.join(path, image_filename[54:-4] + '_tensor_' + str(building_index).zfill(5) + '.npy'), vector)\n",
        "            except:\n",
        "              print(\"didn't work\")\n",
        "              print(image_filename + \": building #\" + str(building_index))\n",
        "        building_index += 1\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 2507/5598 [2:19:44<7:35:16,  8.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "didn't work\n",
            "/content/drive/My Drive/Research Project/train/images/mexico-earthquake_00000023_pre_disaster.png: building #0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 2535/5598 [2:23:15<8:06:30,  9.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "didn't work\n",
            "/content/drive/My Drive/Research Project/train/images/mexico-earthquake_00000042_pre_disaster.png: building #0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5598/5598 [5:42:59<00:00,  3.68s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZAmSh_yjz_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import random\n",
        "# model_post = nn.Linear(in_features=512, out_features=4, bias=True)\n",
        "# model_post_and_pre = nn.Linear(in_features=512*2, out_features=4, bias=True)\n",
        "# model_post_and_pre_and_damage_type = nn.Linear(in_features=512*2+7, out_features=4, bias=True)\n",
        "\n",
        "# post = torch.rand(512)\n",
        "# pre = torch.rand(512)\n",
        "# damage_type = random.randint(0, 6)\n",
        "# print(\"post shape:\", post.shape)\n",
        "# print(\"pre shape:\", pre.shape)\n",
        "# print(\"damage_type:\", damage_type)\n",
        "# val = get_post_output(post)\n",
        "# print(val)\n",
        "# val = get_post_and_pre_output(post, pre)\n",
        "# print(val)\n",
        "# val = get_post_and_pre_output_and_damage_type_output(post, pre, damage_type)\n",
        "# print(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzNGiZenWg89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# def train_model(models, dataloaders, type=\"post_only\"):\n",
        "#     for input, label in dataloaders[\"train\"][type]:\n",
        "#         if type == \"post_only\":\n",
        "#             processed_input = input\n",
        "#         elif type == \"postandpre\":\n",
        "#             processed_input = concat()\n",
        "#         elif type == \n",
        "#         output = models[type](processed_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN3wwZCFlqRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DamageDetectionDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 root_dir : dict, \n",
        "                 input_type = 'post_only', \n",
        "                 equal_distribution = True, \n",
        "                 add_damage_type = False, \n",
        "                 minimum_area = 2000, \n",
        "                 split = 'train'):\n",
        "        assert split in [\"train\", \"val\"]\n",
        "        assert input_type in [\"post_only\", \"pre_and_post\"]\n",
        "        assert add_damage_type in [True, False]\n",
        "        assert equal_distribution in [True, False]\n",
        "        self.root_dir = root_dir\n",
        "        self.input_type = input_type\n",
        "        self.add_damage_type = add_damage_type\n",
        "        self.minimum_area = minimum_area\n",
        "        self.split = split\n",
        "        self.equal_distribution = equal_distribution\n",
        "        self.images = [] #list of tuples\n",
        "        \n",
        "        if self.input_type == 'post_only':\n",
        "            if self.split == 'train':\n",
        "                post_images, _ = split_dataset_post_disaster(self.root_dir, percent_train= 0.8)\n",
        "            else:\n",
        "                _ , post_images = split_dataset_post_disaster(self.root_dir, percent_train = 0.8)\n",
        "\n",
        "            for image_filename in post_images:\n",
        "                building_index = 0\n",
        "                for building in post_images[image_filename]['building_list']:\n",
        "                    bbox = building['bbox']\n",
        "                    if bbox[2] * bbox[3] >= self.minimum_area and building['damage_level'] != 'un-classified': #if it's not blurry\n",
        "                        self.images.append(((image_filename, bbox, building['damage_level'], building_index), 0, post_images[image_filename]['damage_type'])) #0 is placeholder\n",
        "                    building_index += 1\n",
        "                        \n",
        "        elif self.input_type == 'pre_and_post':\n",
        "            if self.split == 'train':\n",
        "                all_images, _ = split_dataset_pre_and_post_disaster(root_dir, percent_train=0.8)\n",
        "            else:\n",
        "                _ , all_images = split_dataset_pre_and_post_disaster(root_dir, percent_train=0.8)\n",
        "            temp_image_list = sorted(list(all_images.keys()))\n",
        "            for i in range(1, len(temp_image_list), 2):\n",
        "                post_image_filename = temp_image_list[i-1]\n",
        "                pre_image_filename = temp_image_list[i]\n",
        "                building_index = 0\n",
        "                for post_building in all_images[post_image_filename]['building_list']:\n",
        "                    post_bbox = post_building['bbox']\n",
        "                    if post_bbox[2] * post_bbox[3] >= self.minimum_area and post_building['damage_level'] != 'un-classified':\n",
        "                        pre_building = all_images[pre_image_filename]['building_list'][building_index] #corresponding pre-disaster building\n",
        "                        pre_bbox = pre_building['bbox']\n",
        "                        post_damage_level = post_building['damage_level']\n",
        "                        post_tuple = (post_image_filename, post_bbox, post_damage_level, building_index)\n",
        "                        pre_tuple = (pre_image_filename, pre_bbox, 0, building_index)\n",
        "                        self.images.append((post_tuple, pre_tuple, all_images[post_image_filename]['damage_type']))\n",
        "                    building_index += 1\n",
        "            \n",
        "            \n",
        "                    \n",
        "        if self.equal_distribution:\n",
        "            random.shuffle(self.images)\n",
        "            if split == 'train': #smaller dataset of equal distribution\n",
        "                per_category = 400\n",
        "            else:\n",
        "                per_category = 100\n",
        "            dest = 0\n",
        "            major = 0\n",
        "            minor = 0\n",
        "            none = 0 #starting with 0 buildings from each category\n",
        "            temp_images = [] #temporary storage\n",
        "            for buildings in self.images: #building is a tuple - if pre_and_post, then it's tuple of length 2 (pair of buildings)\n",
        "                dl = buildings[0][2] #building[0] is always the post image no matter what\n",
        "                if dl == 'un-classified':\n",
        "                    continue\n",
        "                elif dl == 'destroyed' and dest < per_category:\n",
        "                    dest += 1\n",
        "                    temp_images.append(buildings)\n",
        "                elif dl == 'major-damage' and major < per_category:\n",
        "                    major += 1\n",
        "                    temp_images.append(buildings)\n",
        "                elif dl == 'minor-damage' and minor < per_category:\n",
        "                    minor += 1\n",
        "                    temp_images.append(buildings)\n",
        "                elif dl == 'no-damage' and none < per_category:\n",
        "                    none += 1\n",
        "                    temp_images.append(buildings)\n",
        "                if dest == per_category and major == per_category and minor == per_category and none == per_category:\n",
        "                    break\n",
        "            self.images = temp_images #self.images now has an equal distribution of each category of building damage\n",
        "            \n",
        "            \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "            \n",
        "        if self.input_type == \"post_only\":\n",
        "            (image_filename, bbox, damage_level, building_index), _, damage_type = self.images[idx]\n",
        "            path = '/content/drive/My Drive/Research Project/tensors/post'\n",
        "            tensor_filename = os.path.join(path, image_filename[54:-4] + '_tensor_' + building_index.zfill(5) + '.npy')\n",
        "            damage_mapping = {'no-damage' : 0, 'minor-damage' : 1, 'major-damage' : 2, 'destroyed' : 3}\n",
        "            type_mapping = {'earthquake' : 0, 'fire' : 1, 'flooding' : 2, 'tsunami' : 3, 'volcano' : 4, 'wind' : 5}\n",
        "            sample = {'tensor': np.load(tensor_filename), \n",
        "                      'damage_level' : damage_mapping[damage_level], \n",
        "                      'damage_type' : type_mapping[damage_type]}\n",
        "            if add_damage_type:\n",
        "              return sample['tensor'], sample['damage_level'], sample['damage_type']\n",
        "            else:\n",
        "              return sample['tensor'], sample['damage_level']\n",
        "        \n",
        "        elif self.input_type == 'pre_and_post':\n",
        "            (post_image_filename, post_bbox, damage_level, building_index), (pre_image_filename, pre_bbox, _, _), damage_type = self.images[idx]\n",
        "            path = '/content/drive/My Drive/Research Project/tensors/pre'\n",
        "            pre_tensor_filename = os.path.join(path, pre_image_filename[54:-4] + '_tensor_' + str(building_index).zfill(5) + '.npy')\n",
        "            path = '/content/drive/My Drive/Research Project/tensors/post'\n",
        "            post_tensor_filename = os.path.join(path, post_image_filename[54:-4] + '_tensor_' + str(building_index).zfill(5) + '.npy')\n",
        "            damage_mapping = {'no-damage' : 0, 'minor-damage' : 1, 'major-damage' : 2, 'destroyed' : 3}\n",
        "            type_mapping = {'earthquake' : 0, 'fire' : 1, 'flooding' : 2, 'tsunami' : 3, 'volcano' : 4, 'wind' : 5}\n",
        "            sample = {'pre_tensor' : np.load(pre_tensor_filename), \n",
        "                      'post_tensor' : np.load(post_tensor_filename), \n",
        "                      'damage_level' : damage_mapping[damage_level], \n",
        "                      'damage_type' : type_mapping[damage_type]}\n",
        "            if add_damage_type:\n",
        "              return sample['pre_tensor'], sample['post_tensor'], sample['damage_level'], sample['damage_type']\n",
        "            else:\n",
        "              return sample['pre_tensor'], sample['post_tensor'], sample['damage_level']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJy9MVGGlqRc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81c89430-c25b-4590-d6cb-d20cdf7ee466"
      },
      "source": [
        "\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: DamageDetectionDataset(root_dir = root_dir, \n",
        "                                            input_type = input_type, \n",
        "                                            minimum_area = 2000, \n",
        "                                            split = x) for x in ['train', 'val']}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNngdG18Fm-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if input_type == 'post_only':\n",
        "  model_ft = nn.Linear(in_features=512, out_features=4, bias=True)\n",
        "elif input_type == 'pre_and_post':\n",
        "  model_ft = nn.Linear(in_features=512*2, out_features=4, bias=True)\n",
        "elif input_type == 'pre_post_damage_type':\n",
        "  model_ft = nn.Linear(in_features=512*2+7, out_features=4, bias=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JnjK7PglqRu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "e3b935ad-c48f-481f-93ad-937c8ef715b3"
      },
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "learning_rate = 0.001\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=learning_rate, momentum=0.9)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:125: UserWarning: \n",
            "Tesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\n",
            "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
            "If you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
            "\n",
            "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t weight\n",
            "\t bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHRy235BlqR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "w8cqd_AJlqR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "85741699-95e4-4838-b4ec-e62006b7455b"
      },
      "source": [
        "# Train and evaluate\n",
        "\n",
        "# dataloaders = {\n",
        "#     \"train\": {\n",
        "#         \"post_only\": dataloader_post_only\n",
        "#         \"pre_and_post\": dataloader_pre_and_post\n",
        "#         \"pre_post_damge_type\": dataloader_pre_post_damage_type\n",
        "#     }, \n",
        "#     \"val\": {\n",
        "#         \"post_only\": post_model\n",
        "#         \"pre_and_post\": pre_and_post_model\n",
        "#         \"sdffggg\": thirdmodel\n",
        "#     }\n",
        "# }\n",
        "# models = {\n",
        "#     \"post_only\": post_model\n",
        "#     \"pre_and_post\": pre_and_post_model\n",
        "#     \"sdffggg\": thirdmodel\n",
        "# }\n",
        "\n",
        "\n",
        "\n",
        "model_ft, train_acc_hist, val_acc_hist, train_loss_hist, val_loss_hist = train_model(model_ft, \n",
        "                                                                                     dataloaders_dict, \n",
        "                                                                                     criterion, \n",
        "                                                                                     optimizer_ft, \n",
        "                                                                                     num_epochs=num_epochs, \n",
        "                                                                                     model_type = input_type)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/99\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9c0e4f8d3a80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                                                                                      \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                                                                      \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                                                                                      model_type = input_type)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-102cd14bc13b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, model_type, num_epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pre_and_post'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m               \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m               \u001b[0;32mfor\u001b[0m \u001b[0mpre_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                   \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpost_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                   \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-9-97b9434c649f>\", line 121, in __getitem__\n    sample = {'pre_tensor' : np.load(pre_tensor_filename),\n  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\", line 428, in load\n    fid = open(os_fspath(file), \"rb\")\nOSError: [Errno 5] Input/output error: '/content/drive/My Drive/Research Project/tensors/pre/hurricane-michael_00000220_pre_disaster_tensor_00028.npy'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnQgrw4AJ8zO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "2d042703-6613-4bb6-dcbe-1beae02a459d"
      },
      "source": [
        "np.load('/content/drive/My Drive/Research Project/tensors/pre/hurricane-michael_00000220_pre_disaster_tensor_00028.npy')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-675cc4be6de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Research Project/tensors/pre/hurricane-michael_00000220_pre_disaster_tensor_00028.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/My Drive/Research Project/tensors/pre/hurricane-michael_00000220_pre_disaster_tensor_00028.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DcyKrPNlqSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(num_epochs)\n",
        "plt.plot(epochs, train_acc_hist, color = 'blue', label = 'Train')\n",
        "plt.plot(epochs, val_acc_hist, color = 'orange', label = 'Validation')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "epochs = range(num_epochs)\n",
        "plt.plot(epochs, train_loss_hist, color = 'blue', label = 'Train')\n",
        "plt.plot(epochs, val_loss_hist, color = 'orange', label = 'Validation')\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cross Entropy Loss')\n",
        "plt.legend()\n",
        "plt.savefig(\"Cross Entropy Loss\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyVNGEVdlqSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = ''\n",
        "torch.save(model_ft.state_dict(), os.path.join(\"C:/Users/thoma/OneDrive/Damage Detection\", model_name))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}